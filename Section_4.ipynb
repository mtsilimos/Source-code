{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtsilimos/Source-code/blob/main/Section_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6u_eDUxtkcU"
      },
      "outputs": [],
      "source": [
        "# SECTION 4\n",
        "\n",
        "# CONVERSION TO LOWERCASE\n",
        "\n",
        "text = \"She reads many books at HOME and I think she is the quickest READER I know.\"\n",
        "\n",
        "text.lower()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PORTER STEMMER\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmer.stem('active')\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "stemmer.stem('activity')"
      ],
      "metadata": {
        "id": "7J4NlCF1uDEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEM WORDS FROM A TEXT\n",
        "\n",
        "text = '''What Gabriela was experiencing was a cultural clash in expectations. She was used to a more hierarchical\n",
        "framework where the team leader and manager took control and gave specific instructions on how things were to be\n",
        "done. This more directive management style worked well for her and her team in Brazil but did not transfer well to her\n",
        "new team in Sweden, who were more used to a flatter hierarchy where decision making was more democratic. When\n",
        "Gabriela took the issue to her Swedish manager, rather than stepping in with directions about what to do, her manager\n",
        "took on the role of coach and focused on getting her to come up with her own solutions instead.'''\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(text)\n",
        "stemmer = PorterStemmer()\n",
        "for word in words:\n",
        "  print ((word,stemmer.stem(word)))\n"
      ],
      "metadata": {
        "id": "xe-JU_YquPEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SNOWBALL STEMMER\n",
        "\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer('english')\n",
        "stemmer.stem('language')"
      ],
      "metadata": {
        "id": "H9M4hzFzuT4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LEMMATIZATION\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma = WordNetLemmatizer()\n",
        "lemma.lemmatize('runs')\n"
      ],
      "metadata": {
        "id": "I49MZL0gua6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma = WordNetLemmatizer()\n",
        "lemma.lemmatize('better')"
      ],
      "metadata": {
        "id": "uBdevoeCudzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemma = WordNetLemmatizer()\n",
        "lemma.lemmatize('better', pos = 'a')\n"
      ],
      "metadata": {
        "id": "wVeKE3d3ugZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LEMMATIZE WORDS FROM A TEXT\n",
        "\n",
        "text = '''What Gabriela was experiencing was a cultural clash in expectations. She was used to a more\n",
        "hierarchical framework where the team leader and manager took control and gave specific instructions on\n",
        "how things were to be done. This more directive management style worked well for her and her team in\n",
        "Brazil but did not transfer well to her new team in Sweden, who were more used to a flatter hierarchy\n",
        "where decision making was more democratic. When Gabriela took the issue to her Swedish manager,\n",
        "rather than stepping in with directions about what to do, her manager took on the role of coach and\n",
        "focused on getting her to come up with her own solutions instead.'''\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(text)\n",
        "lemma = WordNetLemmatizer()\n",
        "for word in words:\n",
        "  print ((word,lemma.lemmatize(word)))\n"
      ],
      "metadata": {
        "id": "K1NoUFetukqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE STOPWORDS\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text = \"she reads many books at home and i think she is the quickest reader i know\"\n",
        "\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "tokens\n",
        "\n",
        "stopwords.words('english')\n",
        "\n",
        "remove_stopwords= [word for word in tokens if word not in stopwords.words()]\n",
        "remove_stopwords\n"
      ],
      "metadata": {
        "id": "GcfOUja2urU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REMOVE STOP WORDS FROM THE NLTK LIST OF STOP WORDS\n",
        "\n",
        "text = \"but she reads many books at home and i think she is the quickest reader i know\"\n",
        "tokens = word_tokenize(text)\n",
        "new_stopwords = stopwords.words(\"English\")\n",
        "new_stopwords.remove(\"but\")\n",
        "filtered_text = [but for but in tokens if not but in new_stopwords]\n",
        "\n",
        "\n",
        "print(\" \".join(filtered_text))"
      ],
      "metadata": {
        "id": "hdza3MPpuvRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEM A LIST OF WORDS\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "words = ['reads', 'many', 'books', 'home', 'think', 'quickest', 'reader', 'know']\n",
        "\n",
        "for word in words:\n",
        "  print(stemmer.stem(word))\n"
      ],
      "metadata": {
        "id": "Ks2Bqj63u1UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LEMMATIZE WORDS\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "print(lemmatizer.lemmatize(\"reads\"))\n",
        "print(lemmatizer.lemmatize(\"many\"))\n",
        "print(lemmatizer.lemmatize(\"books\"))\n",
        "print(lemmatizer.lemmatize(\"home\"))\n",
        "print(lemmatizer.lemmatize(\"think\"))\n",
        "print(lemmatizer.lemmatize(\"quickest\", pos=\"a\"))\n",
        "print(lemmatizer.lemmatize(\"reader\"))\n",
        "print(lemmatizer.lemmatize(\"know\"))\n"
      ],
      "metadata": {
        "id": "sbHQ1fuwu5Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NORMALISE A TEXT IN ONE GO\n",
        "\n",
        "text = \"she reads MANY BOOKS at home and i think she is the quickest reader i know\"\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import WordNetLemmatizer\n",
        "\n",
        "def norm_text(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [word.lower() for word in tokens]\n",
        "  tokens = [word for word in tokens if not word in stopwords.words(\"english\")]\n",
        "  lemma = WordNetLemmatizer()\n",
        "  tokens = [lemma.lemmatize(word) for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "norm_text(text)\n"
      ],
      "metadata": {
        "id": "IUaQIkJlu8cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Homework\n",
        "\n",
        "# Task 1\n",
        "# Perform stemming (Porter stemmer) in the following text.\n",
        "\n",
        "text1 = 'People might not realise they are part of the disposable clothing problem because they donate their unwanted clothes to charities.'\n",
        "\n",
        "#Task 2\n",
        "# Perform lemmatization in the following text.\n",
        "\n",
        "text2 = '''People might not realise they are part of the disposable clothing problem because they donate their unwanted clothes to\n",
        "charities.'''\n"
      ],
      "metadata": {
        "id": "HtehI-GXQVSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}